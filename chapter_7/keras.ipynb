{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential class\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Second form\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has not yet been created i.e. weights have not been created\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(model.weights)\n",
    "except ValueError:\n",
    "    print(\"Model has not yet been created i.e. weights have not been created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.10926795,  0.27703482, -0.24330038, -0.21311426, -0.08179127,\n",
       "          0.16265273,  0.2768259 , -0.07245703, -0.29558268, -0.055209  ,\n",
       "          0.28337598, -0.24476592,  0.27379966,  0.17333537, -0.05596235,\n",
       "          0.0770095 ,  0.28580475,  0.17886338,  0.25749272,  0.10663608,\n",
       "          0.17044437, -0.0403457 ,  0.14058518, -0.17720518,  0.26108348,\n",
       "          0.21224856,  0.2669248 , -0.20871812,  0.09447911, -0.04317781,\n",
       "         -0.11884663, -0.06586894, -0.24350114,  0.15975624,  0.09519801,\n",
       "          0.13625938,  0.16209295,  0.04590487, -0.1547206 , -0.1983425 ,\n",
       "          0.13476986,  0.28039783, -0.01444194, -0.08128706,  0.1855255 ,\n",
       "         -0.2576043 , -0.28718448,  0.02091315, -0.23625182, -0.10107912,\n",
       "          0.11269397, -0.03593662,  0.09691501,  0.08848345,  0.11551306,\n",
       "         -0.173214  ,  0.29470086,  0.2135818 , -0.23313999,  0.0481177 ,\n",
       "          0.2724951 , -0.01826757,  0.21527976,  0.21784306],\n",
       "        [-0.11423223,  0.04603401,  0.10393095, -0.10970581,  0.22696155,\n",
       "          0.2632265 , -0.26832604, -0.07121879,  0.26661885,  0.10562852,\n",
       "         -0.0653275 , -0.09882168,  0.18890703,  0.12991902, -0.11975081,\n",
       "          0.200596  ,  0.24296147,  0.16140181,  0.22085506, -0.27723506,\n",
       "          0.11892545, -0.14715222,  0.12325326,  0.10744059, -0.09344715,\n",
       "         -0.00189835,  0.21204251,  0.24625134, -0.03248835,  0.16533124,\n",
       "         -0.25345695,  0.1745741 , -0.10720608, -0.09512389,  0.17242491,\n",
       "         -0.29365632,  0.20896405,  0.2346996 ,  0.23292077,  0.21077883,\n",
       "         -0.09583643,  0.15412444, -0.0987432 ,  0.26202005,  0.21045756,\n",
       "         -0.20089445,  0.06629503,  0.26475978, -0.10935898, -0.13918564,\n",
       "          0.20501107, -0.13115071, -0.2021581 , -0.02055863, -0.28461388,\n",
       "          0.21129137, -0.04477045,  0.26186442, -0.27975476, -0.07273728,\n",
       "          0.17734289, -0.06212634,  0.01198182, -0.19716683],\n",
       "        [-0.25376624, -0.24835269, -0.11760503,  0.06381392, -0.07627404,\n",
       "         -0.24038962, -0.22873259, -0.21614368,  0.06924152,  0.15522018,\n",
       "          0.03488824, -0.16008158,  0.20903236,  0.04750276,  0.04046705,\n",
       "         -0.08403151, -0.18266541,  0.0281353 ,  0.0829272 , -0.141883  ,\n",
       "         -0.17136618,  0.28865921,  0.12367427,  0.12313318,  0.20719135,\n",
       "         -0.04123545,  0.06123415,  0.07853198,  0.2512461 ,  0.07441878,\n",
       "          0.09739503,  0.27450955,  0.19011435, -0.08701561,  0.10282519,\n",
       "          0.05592805,  0.0394417 , -0.1988582 ,  0.28893983,  0.1803529 ,\n",
       "          0.2737196 ,  0.28321946,  0.16370896, -0.1219366 , -0.09028846,\n",
       "          0.1450935 ,  0.09305269, -0.16792573,  0.2091732 , -0.21834953,\n",
       "          0.08779702,  0.27211696, -0.06885006, -0.20112048,  0.13716972,\n",
       "          0.02021059,  0.08597386, -0.07572553, -0.0834461 ,  0.290111  ,\n",
       "         -0.10161008,  0.06239918, -0.11747383, -0.16157895]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-8.77038538e-02, -7.56773651e-02,  2.62339681e-01,\n",
       "          2.71096557e-01, -1.75501108e-01, -1.59704283e-01,\n",
       "         -6.41985536e-02, -2.43257999e-01, -1.68719813e-01,\n",
       "          2.15463728e-01],\n",
       "        [-4.67520803e-02,  2.39057034e-01, -3.46492827e-02,\n",
       "         -2.66284227e-01, -1.27908573e-01,  1.29714757e-01,\n",
       "         -2.14914650e-01, -1.26210049e-01, -1.88406080e-01,\n",
       "          2.69215912e-01],\n",
       "        [-2.26226673e-01,  2.06736952e-01,  1.53508246e-01,\n",
       "          8.89137089e-02, -7.28874058e-02, -2.06296891e-01,\n",
       "          1.85590595e-01,  2.88980603e-02,  1.77252322e-01,\n",
       "          4.93614674e-02],\n",
       "        [ 7.31202662e-02,  2.49429673e-01,  2.35510141e-01,\n",
       "          1.01209700e-01, -1.10021099e-01,  1.79311514e-01,\n",
       "          1.03362530e-01, -9.40608531e-02, -2.12078393e-01,\n",
       "         -8.19659978e-02],\n",
       "        [ 8.19695890e-02, -1.37769461e-01, -2.79752195e-01,\n",
       "          6.90378845e-02, -2.09528953e-01,  2.77992219e-01,\n",
       "         -1.02592736e-01, -1.42069757e-01,  1.48453355e-01,\n",
       "         -2.75529474e-01],\n",
       "        [-4.57924604e-02,  1.37017041e-01,  2.16801763e-02,\n",
       "         -1.54178113e-01,  1.83814555e-01, -2.75804311e-01,\n",
       "         -1.71179980e-01, -8.89185220e-02,  8.99797678e-02,\n",
       "          2.53248781e-01],\n",
       "        [ 2.57180899e-01, -2.02078521e-02, -4.85004187e-02,\n",
       "          2.21700639e-01,  2.32529730e-01, -6.21607304e-02,\n",
       "         -2.00467944e-01, -2.09605187e-01, -1.48576781e-01,\n",
       "         -2.64022291e-01],\n",
       "        [ 1.09153390e-01, -2.61560023e-01,  1.18909478e-01,\n",
       "         -1.12444863e-01,  3.47574949e-02, -6.96730614e-02,\n",
       "          2.83006698e-01,  4.87362742e-02, -1.63334176e-01,\n",
       "          1.50485158e-01],\n",
       "        [ 1.94072992e-01, -7.20165223e-02, -2.20543817e-01,\n",
       "         -2.08281085e-01,  6.73654974e-02,  3.33640873e-02,\n",
       "         -1.48916230e-01,  2.79656798e-01, -1.77868813e-01,\n",
       "          1.66839570e-01],\n",
       "        [-3.84572148e-03,  1.89246148e-01, -1.55511513e-01,\n",
       "          2.01896727e-02,  1.15626633e-01, -2.53343940e-01,\n",
       "         -8.72077197e-02, -2.76359916e-01, -9.50035602e-02,\n",
       "          1.24606520e-01],\n",
       "        [ 1.06793165e-01, -9.14479941e-02, -2.26454645e-01,\n",
       "          2.33968347e-01,  2.75324196e-01,  2.13083148e-01,\n",
       "          1.11450225e-01,  2.73901850e-01,  5.95973730e-02,\n",
       "         -9.35166478e-02],\n",
       "        [-2.76135176e-01,  2.42339283e-01,  5.37269413e-02,\n",
       "          7.22792447e-02, -1.87037498e-01, -2.07704574e-01,\n",
       "         -2.73779899e-01, -8.80317539e-02,  2.67976254e-01,\n",
       "         -9.12884623e-02],\n",
       "        [ 6.06271923e-02,  2.09870964e-01,  2.45833904e-01,\n",
       "         -2.63485968e-01,  1.98121220e-01,  7.82910883e-02,\n",
       "          3.32350135e-02, -1.92327619e-01, -2.33744308e-01,\n",
       "         -2.16530263e-02],\n",
       "        [-2.50086904e-01, -8.76183063e-02,  5.29553890e-02,\n",
       "          6.61026239e-02, -1.35947853e-01,  3.76051664e-03,\n",
       "         -2.56473362e-01,  6.42159879e-02,  7.86986947e-02,\n",
       "          8.32145512e-02],\n",
       "        [ 7.15138614e-02, -2.39134490e-01, -1.67154565e-01,\n",
       "         -8.06046873e-02,  4.30844426e-02,  2.76751220e-02,\n",
       "         -1.62842512e-01, -1.10022172e-01,  1.39997184e-01,\n",
       "          2.24075049e-01],\n",
       "        [-2.56917953e-01,  1.98870301e-02,  2.22340137e-01,\n",
       "         -5.74311614e-02, -8.10295343e-02, -9.63182300e-02,\n",
       "          4.35849726e-02, -1.54784843e-01, -9.69491899e-02,\n",
       "          1.26649767e-01],\n",
       "        [ 2.30768949e-01,  1.63874775e-01,  5.50144613e-02,\n",
       "         -8.26969743e-03, -1.62117198e-01,  2.22665757e-01,\n",
       "          2.01423734e-01,  1.31495595e-02,  2.34670788e-01,\n",
       "          2.01116949e-01],\n",
       "        [ 3.85786295e-02,  2.25666255e-01, -2.02623963e-01,\n",
       "          2.80650705e-01,  8.79033208e-02, -2.29105785e-01,\n",
       "         -1.80679217e-01,  1.26438707e-01,  1.18364245e-01,\n",
       "         -2.15939447e-01],\n",
       "        [-1.92207605e-01,  2.99414694e-02,  7.17464089e-03,\n",
       "         -2.00913072e-01, -2.18831390e-01, -5.62349558e-02,\n",
       "         -1.52636558e-01,  6.36759400e-02, -5.23601174e-02,\n",
       "          9.91479158e-02],\n",
       "        [ 2.09372133e-01, -2.79301882e-01,  2.36890018e-02,\n",
       "         -8.78439099e-02,  1.91976428e-01, -2.73763418e-01,\n",
       "          1.04263425e-03,  1.41881704e-01, -2.82635689e-02,\n",
       "          6.09243214e-02],\n",
       "        [-1.76986605e-01,  2.77813464e-01, -2.04447210e-02,\n",
       "          1.29982859e-01,  2.52901584e-01,  7.10982084e-03,\n",
       "          2.34332412e-01, -1.97989911e-01, -1.43481985e-01,\n",
       "         -1.73392072e-01],\n",
       "        [-1.49728864e-01, -2.16618672e-01,  3.83588970e-02,\n",
       "         -2.71139920e-01,  2.50110060e-01,  2.38001376e-01,\n",
       "          2.61155516e-01, -9.51179862e-03, -2.47434199e-01,\n",
       "          2.47245878e-01],\n",
       "        [ 2.47329921e-01, -1.22361228e-01,  1.48753703e-01,\n",
       "          6.53737783e-02, -6.93203807e-02, -1.99003905e-01,\n",
       "          1.33082747e-01, -1.48083568e-02,  2.00204998e-01,\n",
       "          1.03671372e-01],\n",
       "        [-3.01234126e-02, -2.43151486e-02,  1.58972174e-01,\n",
       "         -2.20694542e-01,  1.86527997e-01,  6.14390075e-02,\n",
       "         -1.45927891e-01,  1.97720736e-01,  1.15545571e-01,\n",
       "         -1.14683986e-01],\n",
       "        [-2.01612622e-01, -8.08197707e-02, -5.65808564e-02,\n",
       "          9.19736624e-02, -1.46823347e-01,  2.46753484e-01,\n",
       "         -2.41355479e-01,  2.51102835e-01, -3.36327255e-02,\n",
       "          1.46235496e-01],\n",
       "        [-7.13666826e-02, -3.59791666e-02, -1.50861144e-02,\n",
       "          5.11863232e-02,  2.08667725e-01, -2.45508805e-01,\n",
       "         -2.67602086e-01, -4.29683477e-02, -7.37740397e-02,\n",
       "          2.19686925e-02],\n",
       "        [-2.15218663e-01,  2.37847865e-02,  2.30887085e-01,\n",
       "          1.24592662e-01,  1.26798660e-01, -1.64018691e-01,\n",
       "          1.71299458e-01, -5.89906424e-02, -2.76196599e-02,\n",
       "         -1.88495159e-01],\n",
       "        [ 7.56427348e-02, -1.24879226e-01, -1.56592116e-01,\n",
       "          1.36733055e-04,  1.43820554e-01,  5.30374646e-02,\n",
       "         -1.55739158e-01,  4.90765870e-02, -2.06577480e-01,\n",
       "          2.26290971e-01],\n",
       "        [ 5.39328456e-02, -1.03655130e-01,  7.35355318e-02,\n",
       "          2.22978026e-01,  7.58741200e-02,  3.49128246e-02,\n",
       "         -1.70204207e-01, -1.91227615e-01, -2.68826306e-01,\n",
       "         -8.81688297e-02],\n",
       "        [ 1.78207040e-01, -8.82809013e-02, -1.13941893e-01,\n",
       "         -1.22884572e-01,  1.80570453e-01,  1.71715409e-01,\n",
       "         -9.39565003e-02, -9.22805220e-02, -6.89260066e-02,\n",
       "          1.10672563e-01],\n",
       "        [-5.33092767e-02,  2.45117158e-01, -4.19087410e-02,\n",
       "         -2.76373535e-01, -2.60689348e-01, -1.28976673e-01,\n",
       "         -9.32881981e-02,  2.00159788e-01, -9.63272601e-02,\n",
       "         -2.35236645e-01],\n",
       "        [-1.83722615e-01,  1.29323393e-01,  8.93315673e-02,\n",
       "         -6.53696358e-02, -2.72312641e-01,  9.79969800e-02,\n",
       "         -1.99673906e-01,  2.77614802e-01,  1.09485298e-01,\n",
       "          9.82070267e-02],\n",
       "        [-7.92554617e-02, -6.32187724e-02, -2.06700087e-01,\n",
       "          1.89518243e-01,  6.87575638e-02,  4.79477942e-02,\n",
       "         -2.56106973e-01,  2.38912910e-01,  2.82605499e-01,\n",
       "         -2.43032008e-01],\n",
       "        [ 9.12790895e-02, -1.77482247e-01, -1.07725769e-01,\n",
       "          8.35761130e-02,  8.02214444e-02,  2.59280205e-06,\n",
       "         -1.83015898e-01,  2.30349571e-01,  2.32874483e-01,\n",
       "          2.83778936e-01],\n",
       "        [-1.32999241e-01, -5.19922376e-03, -7.95275569e-02,\n",
       "         -8.11235607e-02, -4.08940613e-02, -1.84225887e-01,\n",
       "          2.36549467e-01,  5.78643084e-02, -1.16503239e-03,\n",
       "          2.37981945e-01],\n",
       "        [ 1.99009746e-01, -1.18049115e-01,  1.72356665e-02,\n",
       "          2.67525345e-01,  1.70785785e-02,  2.29544431e-01,\n",
       "          1.08941853e-01, -2.83713907e-01,  7.50060976e-02,\n",
       "         -1.12139910e-01],\n",
       "        [ 5.47753572e-02,  1.37195855e-01,  2.29517728e-01,\n",
       "         -1.04421467e-01, -2.80578792e-01, -6.70993775e-02,\n",
       "          6.04094565e-02,  5.95983863e-02,  3.15454602e-02,\n",
       "         -1.09629929e-02],\n",
       "        [ 1.14748150e-01, -2.02128157e-01,  1.42052770e-01,\n",
       "          2.69292980e-01,  1.34274870e-01,  1.13754302e-01,\n",
       "          5.98436594e-03,  4.50918078e-03, -9.55667645e-02,\n",
       "          8.55754018e-02],\n",
       "        [-5.41029721e-02,  5.94455004e-02,  8.41701031e-03,\n",
       "          2.34980792e-01, -1.98675245e-01,  1.77887887e-01,\n",
       "          1.32532835e-01,  1.21619999e-01, -2.33586192e-01,\n",
       "          2.32324630e-01],\n",
       "        [-2.02584773e-01,  1.31375402e-01,  1.98678315e-01,\n",
       "         -2.01117843e-01, -2.31705323e-01,  1.79483771e-01,\n",
       "         -1.76303908e-01, -1.62378773e-01,  2.52034515e-01,\n",
       "         -2.33338773e-02],\n",
       "        [ 9.06732678e-03, -2.58227468e-01,  1.51592076e-01,\n",
       "          1.90370172e-01,  1.37471706e-01,  9.91872251e-02,\n",
       "         -2.68303573e-01,  1.19635671e-01, -1.03313714e-01,\n",
       "         -2.26090014e-01],\n",
       "        [ 4.84382510e-02,  1.52738929e-01, -1.04379654e-01,\n",
       "          2.62390047e-01,  2.31817275e-01,  2.75293201e-01,\n",
       "         -2.45692983e-01,  1.28798485e-02,  2.67890990e-02,\n",
       "         -1.06702805e-01],\n",
       "        [-1.29691333e-01,  5.78352809e-03,  1.92495376e-01,\n",
       "         -2.48222947e-02, -1.38486430e-01,  8.00926685e-02,\n",
       "         -1.45493880e-01,  1.76544428e-01, -1.69358581e-01,\n",
       "          2.62538999e-01],\n",
       "        [ 1.52362287e-01, -1.43878251e-01, -5.25903404e-02,\n",
       "          2.68106014e-01,  2.13823885e-01, -2.11873367e-01,\n",
       "         -6.51057512e-02,  1.62436754e-01, -3.07831466e-02,\n",
       "          2.74626166e-01],\n",
       "        [-1.23039842e-01,  1.58548683e-01,  2.72191793e-01,\n",
       "         -2.66996831e-01, -1.78996176e-01,  2.67347485e-01,\n",
       "          2.83145010e-02,  2.74104983e-01, -1.33920893e-01,\n",
       "          2.02220351e-01],\n",
       "        [ 2.48366207e-01,  8.75185728e-02, -1.17370620e-01,\n",
       "         -1.93997219e-01, -2.57815331e-01, -8.05057138e-02,\n",
       "          9.31804478e-02,  1.88633978e-01,  2.49864429e-01,\n",
       "         -8.66014659e-02],\n",
       "        [ 9.17278528e-02,  1.26491398e-01, -2.06598729e-01,\n",
       "          1.43610716e-01, -2.18520582e-01,  8.57569873e-02,\n",
       "          6.06844127e-02,  2.19921142e-01,  1.92980051e-01,\n",
       "         -1.22547716e-01],\n",
       "        [-1.23626605e-01,  1.62621200e-01, -1.29278302e-01,\n",
       "         -2.56700784e-01, -3.66318524e-02, -2.55017012e-01,\n",
       "         -2.59158313e-02,  5.59495687e-02, -1.42065406e-01,\n",
       "         -2.16142505e-01],\n",
       "        [-8.19549412e-02, -1.70319960e-01,  9.72464085e-02,\n",
       "          4.07965779e-02, -1.86777219e-01,  1.30216062e-01,\n",
       "          1.60212785e-01, -2.01692522e-01,  8.08485448e-02,\n",
       "         -2.19791129e-01],\n",
       "        [ 1.60764158e-01,  1.46004945e-01, -1.18973419e-01,\n",
       "          1.69754386e-01,  2.30589896e-01,  1.04895949e-01,\n",
       "          4.25947011e-02, -2.03362525e-01,  4.64246571e-02,\n",
       "         -1.85900927e-03],\n",
       "        [-2.66665131e-01,  2.65486151e-01, -9.33208615e-02,\n",
       "         -1.65122032e-01, -8.92995894e-02, -2.05068022e-01,\n",
       "          1.27149791e-01,  7.26132691e-02,  2.44513959e-01,\n",
       "          1.90590829e-01],\n",
       "        [-2.23932028e-01, -7.63121396e-02,  2.02488869e-01,\n",
       "         -1.11287355e-01, -2.69516557e-01,  2.02242136e-02,\n",
       "         -4.83011752e-02, -1.84675157e-02, -2.50905752e-02,\n",
       "          2.65227228e-01],\n",
       "        [ 1.04485422e-01, -2.81347781e-01,  1.26062870e-01,\n",
       "          1.06746137e-01, -8.39087218e-02,  2.58492082e-01,\n",
       "          5.59214354e-02,  4.33740616e-02, -1.56909555e-01,\n",
       "         -8.60513002e-02],\n",
       "        [ 1.63520813e-01,  8.08998644e-02,  1.75709128e-01,\n",
       "         -1.18751287e-01, -7.20173120e-04, -1.41193777e-01,\n",
       "          1.43090665e-01, -1.46010995e-01, -1.41341984e-01,\n",
       "         -2.04900473e-01],\n",
       "        [-8.41576010e-02,  2.76602536e-01, -2.53284603e-01,\n",
       "         -2.10275859e-01,  1.40815228e-01, -7.86637366e-02,\n",
       "          4.24045324e-02, -1.25681818e-01,  1.89416468e-01,\n",
       "         -2.56584585e-02],\n",
       "        [-2.13339567e-01, -2.69564331e-01, -1.01699859e-01,\n",
       "          1.25401706e-01,  2.22187489e-01,  2.07074970e-01,\n",
       "          1.29704028e-01, -2.42859155e-01,  1.76994205e-02,\n",
       "          1.23136908e-01],\n",
       "        [ 1.09321624e-01, -3.57824266e-02, -9.81000364e-02,\n",
       "          6.18696809e-02,  2.57280469e-03, -2.13255450e-01,\n",
       "         -1.66260540e-01, -9.58064049e-02,  1.34467542e-01,\n",
       "         -2.40933686e-01],\n",
       "        [ 2.43186921e-01, -1.47566184e-01, -1.44243971e-01,\n",
       "          1.50833160e-01, -1.67053342e-02, -2.15699077e-02,\n",
       "          1.34979427e-01, -1.00813836e-01, -3.48351747e-02,\n",
       "          1.42251074e-01],\n",
       "        [ 4.19037938e-02, -1.06096268e-02, -1.74578369e-01,\n",
       "          6.28438890e-02,  6.04000092e-02, -6.95024580e-02,\n",
       "          1.78312808e-01, -2.16196880e-01,  1.60754532e-01,\n",
       "          2.84541637e-01],\n",
       "        [-2.06973270e-01, -1.63356781e-01, -3.89675796e-02,\n",
       "          2.44877845e-01, -2.28993893e-02,  1.14778757e-01,\n",
       "          1.42127395e-01, -3.52828354e-02, -2.16595381e-01,\n",
       "          2.91816294e-02],\n",
       "        [ 2.33822197e-01,  1.52738988e-01, -2.63252437e-01,\n",
       "         -2.22374648e-01,  6.39455914e-02,  1.30948305e-01,\n",
       "          2.36460775e-01,  2.45399177e-02, -2.72443503e-01,\n",
       "         -1.61515087e-01],\n",
       "        [ 1.44841790e-01, -1.91120684e-01, -2.72464633e-01,\n",
       "          4.10672426e-02, -2.45536774e-01,  4.42899466e-02,\n",
       "          5.18332422e-02, -2.38940597e-01,  5.90792298e-03,\n",
       "         -2.16455191e-01],\n",
       "        [-1.44200653e-01, -2.43778914e-01,  1.61371529e-02,\n",
       "         -2.16550589e-01,  8.67794752e-02,  7.99023807e-02,\n",
       "         -3.96829993e-02, -3.92328948e-02,  2.16758460e-01,\n",
       "          1.96079373e-01],\n",
       "        [-2.16421798e-01, -4.51746732e-02, -1.27482504e-01,\n",
       "          1.96869344e-01, -2.45433852e-01,  1.08807713e-01,\n",
       "          2.09801853e-01,  4.86592948e-02,  1.38477683e-01,\n",
       "          1.90203577e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calls a model for the first time to build it\n",
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now a summary can be written\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Input shape can be specified in advance for building on the fly\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two dense layers in the functional API\n",
    "inputs = keras.Input(shape=(3,), name=\"my input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3)\n",
      "(None, 64)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "# Check shape\n",
    "print(inputs.shape)\n",
    "print(features.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-input and multi-output model\n",
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "# Define model inputs\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "# Define features\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(256, activation=\"relu\")(features)\n",
    "features = layers.Dense(256, activation=\"relu\")(features)\n",
    "features = layers.Dense(128, activation=\"relu\")(features)\n",
    "features = layers.Dense(128, activation=\"relu\")(features)\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "# Outputs\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags],\n",
    "                    outputs = [priority, department])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 4s 42ms/step - loss: 93089.5469 - priority_loss: 0.3375 - department_loss: 93089.2031 - priority_mean_absolute_error: 0.5032 - department_accuracy: 0.2675\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 1752540.0000 - priority_loss: 0.3419 - department_loss: 1752539.7500 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2660\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 10607617.0000 - priority_loss: 0.3419 - department_loss: 10607617.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2405\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 40245764.0000 - priority_loss: 0.3419 - department_loss: 40245764.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2420\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 108187304.0000 - priority_loss: 0.3419 - department_loss: 108187304.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2505\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 258628368.0000 - priority_loss: 0.3419 - department_loss: 258628368.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2525\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 507521376.0000 - priority_loss: 0.3419 - department_loss: 507521376.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2465\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 950682368.0000 - priority_loss: 0.3419 - department_loss: 950682368.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2490\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 1691540736.0000 - priority_loss: 0.3419 - department_loss: 1691540736.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2525\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 2753431296.0000 - priority_loss: 0.3419 - department_loss: 2753431296.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2515\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 4260257024.0000 - priority_loss: 0.3419 - department_loss: 4260257024.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2485\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 6585703936.0000 - priority_loss: 0.3419 - department_loss: 6585703936.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2505\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 9674699776.0000 - priority_loss: 0.3419 - department_loss: 9674699776.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2575\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 13627271168.0000 - priority_loss: 0.3419 - department_loss: 13627271168.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2410\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 19723859968.0000 - priority_loss: 0.3419 - department_loss: 19723859968.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2455\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 25538949120.0000 - priority_loss: 0.3419 - department_loss: 25538949120.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2700\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 35147321344.0000 - priority_loss: 0.3419 - department_loss: 35147321344.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2530\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 46245072896.0000 - priority_loss: 0.3419 - department_loss: 46245072896.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2450\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 58437738496.0000 - priority_loss: 0.3419 - department_loss: 58437738496.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2595\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 75155947520.0000 - priority_loss: 0.3419 - department_loss: 75155947520.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2510\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 97783889920.0000 - priority_loss: 0.3419 - department_loss: 97783889920.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2395\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 122703405056.0000 - priority_loss: 0.3419 - department_loss: 122703405056.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2580\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 149725151232.0000 - priority_loss: 0.3419 - department_loss: 149725151232.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2530\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 180923351040.0000 - priority_loss: 0.3419 - department_loss: 180923351040.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2675\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 224764854272.0000 - priority_loss: 0.3419 - department_loss: 224764854272.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2515\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 278698655744.0000 - priority_loss: 0.3419 - department_loss: 278698655744.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2530\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 329217179648.0000 - priority_loss: 0.3419 - department_loss: 329217179648.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2525\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 384970129408.0000 - priority_loss: 0.3419 - department_loss: 384970129408.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2555\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 461180403712.0000 - priority_loss: 0.3419 - department_loss: 461180403712.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2685\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 536720736256.0000 - priority_loss: 0.3419 - department_loss: 536720736256.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2515\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 645780537344.0000 - priority_loss: 0.3419 - department_loss: 645780537344.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2420\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 756206403584.0000 - priority_loss: 0.3419 - department_loss: 756206403584.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2565\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 845854736384.0000 - priority_loss: 0.3419 - department_loss: 845854736384.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2625\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 1004788383744.0000 - priority_loss: 0.3419 - department_loss: 1004788383744.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2630\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 1144108744704.0000 - priority_loss: 0.3419 - department_loss: 1144108744704.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2410\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 1308667150336.0000 - priority_loss: 0.3419 - department_loss: 1308667150336.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2545\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 1497547538432.0000 - priority_loss: 0.3419 - department_loss: 1497547538432.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2585\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 1742233272320.0000 - priority_loss: 0.3419 - department_loss: 1742233272320.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2355\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 1950853103616.0000 - priority_loss: 0.3419 - department_loss: 1950853103616.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2580\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 2219887296512.0000 - priority_loss: 0.3419 - department_loss: 2219887296512.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2585\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 2486888038400.0000 - priority_loss: 0.3419 - department_loss: 2486888038400.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2485\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 2851826565120.0000 - priority_loss: 0.3419 - department_loss: 2851826565120.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2505\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 3181510393856.0000 - priority_loss: 0.3419 - department_loss: 3181510393856.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2525\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 3523622207488.0000 - priority_loss: 0.3419 - department_loss: 3523622207488.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2510\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 4021698428928.0000 - priority_loss: 0.3419 - department_loss: 4021698428928.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2555\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 4377412632576.0000 - priority_loss: 0.3419 - department_loss: 4377412632576.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2615\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 4892124512256.0000 - priority_loss: 0.3419 - department_loss: 4892124512256.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2600\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 5262058455040.0000 - priority_loss: 0.3419 - department_loss: 5262058455040.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2680\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 6107085406208.0000 - priority_loss: 0.3419 - department_loss: 6107085406208.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2540\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 6640197697536.0000 - priority_loss: 0.3419 - department_loss: 6640197697536.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.2650\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 8925784047616.0000 - priority_loss: 0.3419 - department_loss: 8925784047616.0000 - priority_mean_absolute_error: 0.5079 - department_accuracy: 0.0565\n",
      "63/63 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "import numpy as np \n",
    "\n",
    "num_samples = 2000\n",
    "\n",
    "# Dummy data\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "            loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "            metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],[priority_data, department_data],epochs=50)\n",
    "model.evaluate([title_data, text_body_data, tags_data], [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 13ms/step - loss: 24.9196 - output_1_loss: 0.3138 - output_2_loss: 24.6059 - output_1_mean_absolute_error: 0.4800 - output_2_accuracy: 0.2195\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 19.0859 - output_1_loss: 0.3262 - output_2_loss: 18.7597 - output_1_mean_absolute_error: 0.4921 - output_2_accuracy: 0.1345\n",
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Multi-input in a subclassed framework\n",
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    # Init\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(num_departments, activation=\"softmax\")\n",
    "\n",
    "    # Forward pass\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department\n",
    "\n",
    "# Test\n",
    "model = CustomerTicketModel(num_departments=4)\n",
    "priority, department = model({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})\n",
    "model.compile(optimizer=\"rmsprop\", loss=[\"mean_squared_error\", \"categorical_crossentropy\"], \n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\"text_body\": text_body_data,\"tags\": tags_data},\n",
    "          [priority_data, department_data], epochs=1)\n",
    "model.evaluate({\"title\": title_data,\"text_body\": text_body_data,\"tags\": tags_data}, \n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric\n",
    "import tensorflow as tf\n",
    "\n",
    "class customRMS(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None): \n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "    \n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2925 - accuracy: 0.9124 - rmse: 7.1842 - val_loss: 0.1499 - val_accuracy: 0.9573 - val_rmse: 7.3630\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1615 - accuracy: 0.9534 - rmse: 7.3494 - val_loss: 0.1159 - val_accuracy: 0.9676 - val_rmse: 7.4016\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1315 - accuracy: 0.9635 - rmse: 7.3833 - val_loss: 0.1011 - val_accuracy: 0.9727 - val_rmse: 7.4174\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9734 - rmse: 7.4316\n"
     ]
    }
   ],
   "source": [
    "# Toy mnist model for testing\n",
    "from keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\", customRMS()])\n",
    "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "903db93db347b6cc4711a3ce3dd580256d2eecd4e3d421c66e7174fdec8ffda9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
